{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marukos/Decision-Trees/blob/main/DecisionTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrcOVDGnyDI"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that.\n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJWwHpJnyDK"
      },
      "outputs": [],
      "source": [
        "NAME = \"Markos Koletsas\"\n",
        "AEM = \"3557\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgauGbInyDM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_FF68cfznyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ce63642cafb413e7903d83d2f2cd3637",
          "grade": false,
          "grade_id": "cell-f62db6dce1ed3f2e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 2 - Decision Trees #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zq29ctnanyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
          "grade": false,
          "grade_id": "cell-dce2e73cee9a5017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mb4Wf4IdnyDP",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
          "grade": false,
          "grade_id": "cell-83ca2b0456fb85db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "After this assignment you will:\n",
        "- Be able to use the scikit-learn library and train your own model from scratch.\n",
        "- Be able to train and understand decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sLqpxgvbnyDQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "396c39a0797964c378ebb90cf18a29de",
          "grade": false,
          "grade_id": "cell-2cef6d48eea484d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
        "RANDOM_VARIABLE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLqRTrLTnyDR"
      },
      "source": [
        "## 1. Scikit-Learn and Decision Trees ##\n",
        "\n",
        "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d5K-BdnyDS"
      },
      "source": [
        "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "NfF54h6anyDS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4b873328ea05f6ef9c08827168c7b835",
          "grade": false,
          "grade_id": "cell-1f0c2f3918333cf6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from pandas.core.common import random_state\n",
        "# BEGIN CODE HERE\n",
        "X, y = load_breast_cancer().data, load_breast_cancer().target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_VARIABLE, test_size=0.33)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "FiOtzHkpnyDT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
          "grade": true,
          "grade_id": "cell-3f43c895ceaf57a9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "9d9e6998-2c8e-437c-d222-188ee7d3eed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of train set:381\n",
            "Size of test set:188\n",
            "Unique classes:2\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of train set:{}\".format(len(y_train)))\n",
        "print(\"Size of test set:{}\".format(len(y_test)))\n",
        "print(\"Unique classes:{}\".format(len(set(y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JuW_lKVFnyDU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
          "grade": false,
          "grade_id": "cell-1ce621a108e76a15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "Size of train set:381  \n",
        "Size of test set:188  \n",
        "Unique classes:2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUB8sl0NnyDV"
      },
      "source": [
        "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "nPQFaOhLnyDW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17197b62614427a979fcbab7ed2734dd",
          "grade": false,
          "grade_id": "cell-a7fa1d29509eb2a1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "classifier_gini = DecisionTreeClassifier(random_state=RANDOM_VARIABLE, criterion='gini')\n",
        "classifier_igain = DecisionTreeClassifier(random_state=RANDOM_VARIABLE, criterion='entropy')\n",
        "\n",
        "classifier_gini.fit(X_train, y_train)\n",
        "classifier_igain.fit(X_train, y_train)\n",
        "\n",
        "prediction_gini = classifier_gini.predict(X_test)\n",
        "prediction_igain = classifier_igain.predict(X_test)\n",
        "\n",
        "f_measure_gini = f1_score(prediction_gini,y_test)\n",
        "f_measure_igain = f1_score(prediction_igain,y_test)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "qToIpGtnnyDX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d9aab4355c27c346f7e6548f233e758",
          "grade": true,
          "grade_id": "cell-09657a82bf4028c4",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "c22238a1-81d8-4d4f-a5be-2051c5945da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F-Measure Gini: 0.9372384937238494\n",
            "F-Measure Information Gain: 0.9596774193548386\n"
          ]
        }
      ],
      "source": [
        "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
        "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hn9nblQ5nyDY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
          "grade": false,
          "grade_id": "cell-b0d8630f3b764cf3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "F-Measure Gini: 0.9372384937238494\n",
        "F-Measure Information Gain: 0.9596774193548386\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "31Iyi9SJnyDZ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
          "grade": false,
          "grade_id": "cell-591ba122016b6db5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "U7gSfRu_nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54cf257e90a3cb5877db81297bedd45c",
          "grade": false,
          "grade_id": "cell-31c58b6161a3907d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "depth = classifier_gini.get_depth()\n",
        "fscores = {}\n",
        "fscores['train'] = []\n",
        "fscores['test'] = []\n",
        "\n",
        "for i in range(0, depth):\n",
        "    classifier_gini2 = DecisionTreeClassifier(random_state=RANDOM_VARIABLE, criterion='gini', max_depth=i+1)\n",
        "    classifier_gini2.fit(X_train, y_train)\n",
        "    prediction_gini_train = classifier_gini2.predict(X_train)\n",
        "    prediction_gini_test = classifier_gini2.predict(X_test)\n",
        "    f_measure_gini_train = f1_score(prediction_gini_train,y_train)\n",
        "    f_measure_gini_test = f1_score(prediction_gini_test,y_test)\n",
        "    fscores['train'].append(round(f_measure_gini_train*100,2))\n",
        "    fscores['test'].append(round(f_measure_gini_test*100,2))\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "2395Por-nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70a249937f2f690c6ce855debaed204c",
          "grade": true,
          "grade_id": "cell-0c300109423f53b9",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "87c28091-a423-4c0b-c01c-a49bdf8aa793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
            "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
          ]
        }
      ],
      "source": [
        "print(\"Fscores Train: {}\".format(fscores['train']))\n",
        "print(\"Fscores Test:  {}\".format(fscores['test']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f37yzYcbnyDb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
          "grade": false,
          "grade_id": "cell-75789627f20d2c94",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "```\n",
        "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
        "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4stz0V9knyDd",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bca7d4c160c767d27a09b4620d27d56e",
          "grade": false,
          "grade_id": "cell-5906e6d5efa70282",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "kwtDaX3JnyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
          "grade": true,
          "grade_id": "cell-c9c6ea0e40d98b83",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Παρατηρούμε πως το score κατά την εκπαίδευση συνεχώς αυξάνεται, όσο αυξάνουμε και το βάθος με αποτέλεσμα να καταφέρνει να φτάσει μέχρι και το 100%. Παρόλα αυτά είμαστε βέβαιοι πριν καν μελετήσουμε τα αποτελέσματα κατά τον έλεγχο πως πρόκειται για μια περίπτωση υπερεκπαίδευσης.\n",
        "\n",
        "Προχωρώντας και μελετώντας και τα αποτελέσματα κατά τον έλεγχο παρατηρούμε πως η υπόθεση μας ήταν σωστή. Μέχρι και το μέγιστο_βάθος=3 το ποσοστό επιτυχίας αυξάνεται, ωστόσο αυτό αποτελεί σημείο καμπής και ύστερα αρχίζει να μειώνεται σημειώνοντας σημαντική πτώση από 96.64% σε 93.72%.\n",
        "\n",
        "Επομένως, η τιμή που θα επιλέγαμε θα ήταν μέγιστο_βάθος=3, καθώς μας ενδιαφέρει περισσότερο το ποσοστό επιτυχίας κατά τον έλεγχο (δηλαδή σε άγνωστα δεδομένα), παρά κατά την εκπαίδευση."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PIw1fVFenyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
          "grade": false,
          "grade_id": "cell-9ef42e6c90ea2ffe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2.0 Pipelines ##\n",
        "\n",
        "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jJW-avitO9E"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "train_set = pd.read_csv('income.csv').drop('income', axis=1)\n",
        "y_train = pd.read_csv('income.csv')['income']\n",
        "y_train = pd.DataFrame(columns=['income'], data=y_train)\n",
        "# any other code you need\n",
        "encoder = OrdinalEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "\n",
        "test_set = pd.read_csv('income_test.csv').drop('income', axis=1)\n",
        "y_test = pd.read_csv('income_test.csv')['income'].values\n",
        "y_test = pd.DataFrame(columns=['income'], data= y_test)\n",
        "# any other code you need\n",
        "y_test = encoder.transform(y_test)\n",
        "# End CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akVGpGHDuav4"
      },
      "source": [
        "**2.2** Create and test your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv6z98huuZ6M"
      },
      "outputs": [],
      "source": [
        "#Your pipeline\n",
        "numeric_features = [\"hours-per-week\", \"age\",\"education_num\",\"capital-gain\",\"capital-loss\"]\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\"))]\n",
        ")\n",
        "\n",
        "nan_numeric_values = [\"fnlwgt\"]\n",
        "nan_numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))]\n",
        ")\n",
        "\n",
        "categorical_features = ['marital-status', 'education', 'relationship', 'sex', 'race', 'workclass', 'occupation']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "           (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "           (\"encoder\", OneHotEncoder())\n",
        "])\n",
        "\n",
        "ordinal_features = []\n",
        "ordinal_transformer = Pipeline (\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "           (\"encoder\", OrdinalEncoder())]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"num_fw\", nan_numeric_transformer, nan_numeric_values),\n",
        "        (\"one_hot_cat\", categorical_transformer, categorical_features),\n",
        "        (\"ordinal_cat\", ordinal_transformer,ordinal_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier(random_state=RANDOM_VARIABLE))]\n",
        ")\n",
        "\n",
        "clf.fit(train_set, y_train)\n",
        "y_predict =  clf.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uaArYmQvKcf",
        "outputId": "773a75b7-3b44-4476-b999-484044f1b30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Accuracy: 0.806\n",
            "Model score F1 Weighted: 0.807\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_MWnYY2r3-"
      },
      "source": [
        "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "RNECyUFtnyDf",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
          "grade": true,
          "grade_id": "cell-dd950ab2eb40d8a4",
          "locked": false,
          "points": 45,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "16711fc0-b8d7-4540-a217-3b4b8780080e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params:\n",
            "{'classifier__criterion': 'gini', 'classifier__max_depth': 35, 'classifier__max_features': None, 'classifier__max_leaf_nodes': 90, 'classifier__min_samples_leaf': 7, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
        "    \"classifier__max_depth\": [10, 19, 35],\n",
        "    \"classifier__criterion\": [\"gini\",\"entropy\"],\n",
        "    \"classifier__max_features\": [0.25, 0.5, 0.75, None],\n",
        "    \"classifier__min_samples_leaf\": [1, 3, 7],\n",
        "    \"classifier__max_leaf_nodes\": [70, 80, 90, 105]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid_search.fit(train_set, y_train)\n",
        "y_predict =  grid_search.predict(test_set)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhE0haFuw57D",
        "outputId": "df017a6c-7f04-477f-cc78-11828d178d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Accuracy: 0.857\n",
            "Model score F1 Weighted: 0.853\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f_lIQ1-wnyDg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee9d4c2635307395bdef2efb941106ae",
          "grade": false,
          "grade_id": "cell-2c3327274958bbad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following\n",
        "- How do you handle missing values and why\n",
        "- How do you handle categorical variables and why\n",
        "- Any further preprocessing steps\n",
        "- How do you evaluate your model and how did you choose its parameters\n",
        "- Report any additional results and comments on your approach.\n",
        "\n",
        "You should achieve at least 85% accuracy score and 84% f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "76FF0gYVnyDh",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
          "grade": true,
          "grade_id": "cell-80274fd09b80518c",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Αφού φορτώσουμε το dataset, η πρώτη κίνηση μας είναι να μετατρέψουμε τους στόχους μας (δηλαδή το y_train και το y_test) σε συνεχείς τιμές, οπότε πλέον από \"<=50Κ\" και \">50Κ\" οι κλάσεις μας θα ορίζονται από 0 και 1, αυτό το πετυχαίνουμε χρησιμοποιώντας ένας Ordinal Encoder. Το πρώτο εμπόδιο μας είναι τα missing values.\n",
        "\n",
        "Στο συγκεκριμένο dataset υπάρχουν μόνο κατηγορηματικές τιμές που λείπουν, παρόλα αυτά το αγνοήσαμε αυτό και για λόγους εξάσκησης είδαμε πως θα αντιμετωπίζαμε και τις αριθμητικές τιμές που λείπουν.\n",
        "*   Για τις αριθμητικές μεταβλητές λάβαμε δύο χωριστές περιπτώσεις, μια ήταν αυτή στην οποία θέλαμε να δώσουμε σε όλα τα missing values τη μέση τιμή της συγκεκριμένης μεταβλητής και στην άλλη κατηγορία όσες θέλαμε να έχουμε τη πιο συχνά χρησιμοποιούμενη τιμή. Στην δεύτερη περίπτωση άνηκε μόνο η μεταβλητή fnlwgt, καθώς αυτός ο αριθμός προσδίδει χαρακτηριστικά στο συγκεκριμένο άτομο και δεν έχει αριθμητική αξία που μας νοιάζει το μέγεθος της. Όλες οι υπόλοιπες αριθμητικές μεταβλητές αντιμετωπίστηκαν με τη στρατηγική του mean.\n",
        "*   Για τις κατηγορηματικές μεταβλητές χρησιμοποιήσαμε σε όλες τη στρατηγική του most frequent, γιατί διαφορετικά η μόνη άλλη στρατηγική που μπορεί να χρησιμοποιηθεί είναι αυτή που ορίζουμε σε όλα τα missing values μιας μεταβλητής την ίδια τιμή. Ωστόσο, αυτή η στρατηγική θα μπορούσε να χρησιμοποιηθεί μόνο από έναν ειδικό του πεδίου και μπορεί πάλι να μην έδινε ικανοποιητικα αποτελέσματα.\n",
        "\n",
        "Αφού πλέον δεν υπάρχουν κενές τιμές έχει σειρά να μετατρέψουμε όλες τις κατηγορηματικές μεταβλητές σε αριθμητικές, ώστε να είναι συμβατές με το Decision Tree Classifier που μας προμηθεύει η βιβλιοθήκη scikit learn. Πάλι πρέπει να χωρίσουμε τις κατηγορηματικές μας μεταβλητές σε δύο ομάδες, αυτές στις οποίες θα χρησιμοποιήσουμε Ordinal Encoder και αυτές στις οποίες θα χρησιμοποιήσουμε One Hot Encoder. Αυτή τη φορά όμως αντί να διαλέξουμε πως θα γίνει ο χωρισμός αυτός βάσει της λογικής χρησιμοποιήσαμε brute force και ελέγξαμε την απόδοση του μοντέλου για κάθε δυνατό συνδυασμό (όχι μεταθέσεις λόγω της αυξημένης χρονικής πολυπλοκότητας). Αυτή η διαδικασία έγινε δύο φορές μία χωρίς να δώσουμε παραμέτρους στο μοντέλο μας και μία με τις παραμέτρους που προέκυψαν από το grid search. Ο κώδικας για τη συγκεκριμένη διαδικασία υπάρχει στο τέλος του notebook.\n",
        "\n",
        "Ξεκινήσαμε επιλέγοντας για ποιες παραμέτρους θέλουμε να βρούμε τις βέλτιστες τιμές. Αφού διαλέξαμε τις παραμέτρους σύμφωνα με το ποιες θεωρήσαμε οι ίδιοι πως έχουν τη μεγαλύτερη βαρύτητα, έπρεπε να διαλέξαμε ορισμένες τιμές για τις οποίες θέλαμε να δούμε την απόδοση του μοντέλου μας. Τη πρώτη φορά κινηθήκαμε χωρίζοντας, όπου ήταν εφικτό, το διάστημα από το 1 μέχρι τη τιμή που είχε δώσει το αρχικό μας μοντέλο στη συγκεκριμένη παράμετρο. Ύστερα, βλέποντας τα αποτελέσματα και τις τιμές που επιλέγονταν για κάθε παράμετρο επαναλαμβάναμε τη διαδικασία για τιμές πλέον πιο κοντά σε αυτή που πετυχέναμε τη μέγιστη απόδοση.\n",
        "\n",
        "Αφού ρυθμίσουμε τις παραμέτρους του Pipeline εκτελούμε ξανά το brute force αλγόριθμο για να αλλάξουμε ποιες κατηγορηματικές μεταβλητές θα γίνουν transform με ordinal encoder και ποιες με one hot encoder. Παραδόξως, μας εμφανίζει πως τα καλύτερα αποτελέσματα τα λαμβανουμε αν χρησιμοποιήσουμε μόνο τον One hot encoder.\n",
        "\n",
        "Έτσι, καταφέραμε να αυξήσουμε την απόδοση μας ελάχιστα και να τη φέρουμε στο 85.7% accuracy score και 85.2% f1 score.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mNqPY_yanyDj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cef3f333ab449ed91b81ea96695e712",
          "grade": false,
          "grade_id": "cell-555d20216f9bbec2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3.0 Common Issues ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyDSnDCnyDk"
      },
      "source": [
        "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "G9M3JhlpnyDl",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
          "grade": false,
          "grade_id": "cell-d7f58621bad12aad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "2048a369-3d50-4db2-ec75-ba7f5fb4c830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score accuracy: 0.791\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# Create X and y\n",
        "X_train = data.drop([\"income\"],axis=1)\n",
        "y_train = data['income'].values\n",
        "X_test = data_test.drop([\"income\"],axis=1)\n",
        "y_test = data_test['income'].values\n",
        "# Classifier\n",
        "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "classifier.fit(X_train,y_train)\n",
        "y_predict = classifier.predict(X_test)\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Yal5vVVInyDo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c3981752b539236e99415ab6e2cbea1f",
          "grade": false,
          "grade_id": "cell-9b18d6c4e381a9f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "4HaPGUuUnyDo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12b88026c150b617074a5c06fea36b73",
          "grade": true,
          "grade_id": "cell-905e7dceeb4172c3",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score, accuracy_score\n",
        "# y_predict = classifier.predict(X_test)\n",
        "\n",
        "# BEGIN CODE HERE\n",
        "metric1 = balanced_accuracy_score(y_test,y_predict)\n",
        "metric2 = average_precision_score(y_test,y_predict)\n",
        "metric3 = f1_score(y_test,y_predict,average = \"binary\")\n",
        "# END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H03BYlAC6B5u",
        "outputId": "460ee75a-be09-43aa-f1bf-08da1072e8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score Metric 1: 0.688\n",
            "Model score Metric 2: 0.414\n",
            "Model score Metric 3: 0.533\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YJxhaPxdnyDr",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
          "grade": false,
          "grade_id": "cell-1f23f3e27600f019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "PIEyNQJsnyDt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "baff993106fd2b655fd47d05c75ea4ce",
          "grade": true,
          "grade_id": "cell-d60d7e6175d184e9",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Το κυριότερο πρόβλημα του κατηγοριοποιητή μας είναι η απουσία ρύθμισης των υπερπαραμέτρων του, επομένως έχοντας της default υπερπαραμέτρους της κλάσης του αυτές πολύ πιθανόν να μην είναι οι κατάλληλες για τα δεδομένα μας. Ένας τρόπος για να επιλυθεί θα ήταν να εφαρμόσουμε grid search.\n",
        "\n",
        "Επίσης, ένα άλλο πρόβλημα που ενδέχεται να υπάρχει είναι πως τα δεδομένα μπορεί να μην είναι ομοιόμορφα χωρισμένα, δηλαδή για τη μεταβλητή income που έχει τιμές 0 και 1, το train set μας να αποτελείται από 80% 0, ενώ το test set μας από 20% 0. Με αποτέλεσμα να μη μπορεί να γίνει το κατάλληλο fitting. Για να το λύσουμε αυτό θα κάνουμε stratification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WCN7E_ctnyDu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "747645b33cb4f5c14796504fac6bf3ce",
          "grade": false,
          "grade_id": "cell-89715acd6c51b332",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "g9Wzx0bknyDv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccd1d12620f1a3e1c7b026b862056546",
          "grade": true,
          "grade_id": "cell-f44811f1e99ee41e",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "8bd092d9-ea50-4a82-abf4-651a3cbf1e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params:\n",
            "{'criterion': 'gini', 'max_depth': 12, 'max_features': None, 'max_leaf_nodes': 60, 'min_samples_leaf': 1, 'random_state': 42}\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "final_score = \"0.836\"\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv', usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "data = pd.concat([data, data_test])\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits = 10, test_size = data_test.shape[0]/data.shape[0] ,\n",
        "                             random_state = RANDOM_VARIABLE)\n",
        "X = data.drop([\"income\"],axis=1).values\n",
        "y = data['income'].values\n",
        "best = [0.0,[],[],[],[]]\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "    classifier.fit(X_train,y_train)\n",
        "    y_predict = classifier.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test,y_predict)\n",
        "    if acc_score > best[0]:\n",
        "        best[0] = acc_score\n",
        "        best[1] = X_train\n",
        "        best[2] = y_train\n",
        "        best[3] = X_test\n",
        "        best[4] = y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = best[1:]\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [1, 12, 25, 50],\n",
        "    \"criterion\": [\"gini\",\"entropy\"],\n",
        "    \"max_features\": [0.25, 0.5, 0.75, None],\n",
        "    \"min_samples_leaf\": [1, 5, 10],\n",
        "    \"max_leaf_nodes\": [30, 60, 90],\n",
        "    \"random_state\": [RANDOM_VARIABLE]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "y_predict = grid_search.predict(X_test)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "classifier.set_params(**grid_search.best_params_)\n",
        "best = [0.0,[],[],[],[]]\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  classifier.fit(X_train,y_train)\n",
        "  y_predict = classifier.predict(X_test)\n",
        "  acc_score = accuracy_score(y_test,y_predict)\n",
        "  if acc_score > best[0]:\n",
        "    best[0] = acc_score\n",
        "    best[1] = X_train\n",
        "    best[2] = y_train\n",
        "    best[3] = X_test\n",
        "    best[4] = y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = best[1:]\n",
        "classifier.fit(X_train,y_train)\n",
        "y_predict = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "metric1 = balanced_accuracy_score(y_test,y_predict)\n",
        "metric2 = average_precision_score(y_test,y_predict)\n",
        "metric3 = f1_score(y_test,y_predict,average = \"binary\")\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoDBPL6n6LLI",
        "outputId": "6de2d6ad-c77d-4e62-85e7-024e96972f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score accuracy: 0.836\n",
            "Model score Metric 1: 0.711\n",
            "Model score Metric 2: 0.488\n",
            "Model score Metric 3: 0.581\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "ZyG7hhbFnyDx",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b26041c1723d2858ad0833f8985801db",
          "grade": true,
          "grade_id": "cell-c99ca88f33f3717c",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "Ξεκινάμε φορτώνοντας τις συναρτήσεις που θα χρειαστούμε, καθώς και το μέρος του dataset που επιλέξαμε να χρησιμοποιήσουμε (δηλαδή μόνο τις αριθμητικές τιμές) και παράλληλα κάνουμε και την κατάλληλη προεπεξεργασία στη μεταβλητή income για να της δώσουμε τη μορφή που επιθυμούμε.\n",
        "\n",
        "Ύστερα συνενώνουμε τα δύο μέρη του dataset (train-set και test-set) σε ένα ενιαίο για να εφαρμόσουμε στρωματοποίηση και να το χωρίσουμε κατάλληλα εκ νέου σε train-set και test-set διατηρώντας το μέγεθος που είχαν και προηγουμένως. Έτσι, θα υπάρχει τέτοιος διαχωρισμός, όπου θα έχουμε σχεδόν το ίδιο ποσοστό κάθε τιμής κάθε μεταβλητής μεταξύ test-set και train-set.\n",
        "\n",
        "Θα δημιουργήσουμε δέκα διαφορετικούς τέτοιους διαχωρισμούς και θα μετρήσουμε το accuracy για κάθε έναν από αυτούς με τον classifier που μας δίνεται, όποιος πετύχει το μεγαλύτερο score είναι και αυτός που θα κρατήσουμε.\n",
        "\n",
        "Έπειτα, εκτελούμε grid search όπως είχε περιγραφεί και στο από πάνω ερώτημα. Διαλέγουμε ορισμένες παραμέτρους και διεξάγουμε πειράματα, ώσπου να βρούμε τις τιμές για ένα τοπικό μέγιστο στο οποίο θα συγκλίνει το μοντέλο μας. Αφού κάνουμε και αυτό το βήμα, εκτελούμε ξανά το προηγούμενο για να βρούμε το νέο διαχωρισμό του dataset μας που θα εξυπηρετεί το συγκεκριμένο μοντέλο μας, καθώς πλέον έχουμε αλλάξει τις παραμέτρους του.\n",
        "\n",
        "Τέλος, υπολογίζουμε ξανά τις μετρικές μας για να δούμε κατά πόσο καταφέραμε να τις βελτιώσουμε.\n",
        "\n",
        "Αφού δεν ορίζεται random_state στον classifier που μας δόθηκε το αριστερό μέρος μονάχα μπορεί να διαφέρει από run σε run, αλλά συνήθως θα είναι σε ακρίβεια τρίτου δεκαδικού ψηφίου. Τα τελικά μας αποτελέσματα ήταν τα εξής για το συγκεκριμένο run:\n",
        "\n",
        "*   accuracy_score:          0.792 ➔ 0.836\n",
        "*   average_precision_score: 0.415 ➔ 0.488\n",
        "*   balanced_accuracy_score: 0.688 ➔ 0.711\n",
        "*   f1_score (binary):       0.534 ➔ 0.581\n",
        "\n",
        "Επομένως, παρατηρούμε αύξηση σε όλες τις προηγούμενες μετρικές μας.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTU9h63tUKbv"
      },
      "source": [
        "# Πρόχειρο"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQVQ2pI8ZY83",
        "outputId": "cb49e5f9-81e9-4ab7-c942-23ec8a353075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[['education', 'workclass', 'sex', 'race', 'marital-status'], 0.7544237675481554, 0.6540372762486302, ['relationship', 'occupation']], [['workclass', 'race', 'marital-status', 'occupation'], 0.7535749265426053, 0.6566236312895299, ['education', 'sex', 'relationship']], [['education', 'workclass', 'sex', 'race', 'marital-status', 'occupation'], 0.7539014038524322, 0.6556420917541126, ['relationship']]]\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "from sklearn.metrics import accuracy_score\n",
        "strings = {\"occupation\", \"education\", \"marital-status\",\"workclass\",\"race\", \"sex\", \"relationship\"}\n",
        "max = [[{}, 0.0, 0.0,{}],[{}, 0.0, 0.0,{}],[{}, 0.0, 0.0,{}]]\n",
        "for i in range (0,8):\n",
        "  a = list(combinations(strings, 7-i))\n",
        "  for j in a:\n",
        "    categorical_features = list(j)\n",
        "    for k in combinations(strings.difference(j), len(strings.difference(j))):\n",
        "      ordinal_features = list(k)\n",
        "\n",
        "      preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", numeric_transformer, numeric_features),\n",
        "          (\"num_fw\", nan_numeric_transformer, nan_numeric_values),\n",
        "          (\"one_hot_cat\", categorical_transformer, categorical_features),\n",
        "          (\"ordinal_cat\", ordinal_transformer,ordinal_features)\n",
        "        ]\n",
        "      )\n",
        "\n",
        "\n",
        "      clf = Pipeline(\n",
        "        steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier(random_state=RANDOM_VARIABLE,\n",
        "                                                                                      max_depth = 24,\n",
        "                                                                                      criterion =\"gini\",\n",
        "                                                                                      max_features = None,\n",
        "                                                                                      min_samples_leaf = 4,\n",
        "                                                                                      max_leaf_nodes = 95))]\n",
        "      )\n",
        "      clf.fit(train_set, y_train)\n",
        "      y_predict =  clf.predict(test_set)\n",
        "      if accuracy_score(y_test, y_predict) > max[0][1]:\n",
        "        max[0][0] = categorical_features\n",
        "        max[0][1] = accuracy_score(y_test, y_predict)\n",
        "        max[0][2] = f1_score(y_test, y_predict,average='weighted')\n",
        "        max[0][3] = ordinal_features\n",
        "      if f1_score(y_test, y_predict,average='weighted') > max[1][2]:\n",
        "        max[1][0] = categorical_features\n",
        "        max[1][1] = accuracy_score(y_test, y_predict)\n",
        "        max[1][2] = f1_score(y_test, y_predict,average='weighted')\n",
        "        max[1][3] = ordinal_features\n",
        "      if accuracy_score(y_test, y_predict) > max[2][1] and f1_score(y_test, y_predict,average='weighted') > max[2][2]:\n",
        "          max[2][0] = categorical_features\n",
        "          max[2][1] = accuracy_score(y_test, y_predict)\n",
        "          max[2][2] = f1_score(y_test, y_predict,average='weighted')\n",
        "          max[2][3] = ordinal_features\n",
        "\n",
        "print(max)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}